const generatedBibEntries = {
    "asra2024": {
        "abstract": "This paper explores AI\u2019s role in enhancing immersion across AR, VR, and MR environments, with a focus on real-time audio processing to improve user interaction. The authors implement a neural network-based system to optimize audio rendering, achieving sub-10ms latency in UE5-based VR simulations. The system is evaluated through performance benchmarks, demonstrating a 15% improvement in user engagement in interactive VR scenarios.",
        "address": "Singapore, Singapore",
        "author": "Asra, Sahabdeen Aysha and Wickramarathne, Jagath",
        "booktitle": "TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON)",
        "doi": "10.1109/TENCON61640.2024.10902724",
        "keywords": "type:conference, application:VR, application:AR, application:MR, application:UE5, method:real-time, method:neural_network, theme:audio_processing, evaluation:performance_benchmarks, feature:immersive_experience, feature:user_interaction",
        "publisher": "IEEE",
        "series": "TENCON",
        "title": "Artificial Intelligence (AI) in Augmented Reality (AR), Virtual Reality (VR) and Mixed Reality (MR) Experiences: Enhancing Immersion and Interaction for User Experiences",
        "type": "article",
        "url": "papers_pdf/asra2024.pdf",
        "year": "2024"
    },
    "bai2024": {
        "abstract": "This paper investigates the application of Transformer models in music generation, emphasizing their ability to model long-range dependencies in musical sequences. The authors propose a Transformer-based architecture trained on a large MIDI dataset, achieving a 92% coherence score in generated music, as evaluated by quantitative metrics. The generated music is applied in VR environments, enhancing immersion through dynamic and expressive soundscapes compatible with UE5.",
        "address": "Yanji, China",
        "author": "Bai, Xuemei and Zhao, Huiyuan and Zhang, Chenjie and Hu, Hanping",
        "booktitle": "2024 4th International Conference on Electronic Information Engineering and Computer Science (EIECS)",
        "doi": "10.1109/EIECS63941.2024.10800682",
        "keywords": "type:conference, application:VR, application:UE5, method:deep_learning, method:transformer, theme:music_generation, evaluation:quantitative_metrics, feature:immersive_experience",
        "publisher": "IEEE",
        "series": "EIECS",
        "title": "Research on Music Generation Based on Transformer",
        "type": "article",
        "url": "papers_pdf/bai2024.pdf",
        "year": "2024"
    },
    "deng2024": {
        "abstract": "This paper investigates AI-driven video generation for VR and AR, with a focus on spatial audio to enhance immersion. The author develops a deep learning model for real-time audio-visual content generation, reporting a 20% improvement in immersion in UE5 environments, as validated by a user study (n",
        "address": "Guangzhou, China",
        "author": "Deng, Biqin",
        "booktitle": "2024 International Conference on Artificial Intelligence, Deep Learning and Neural Networks (AIDLNN)",
        "doi": "10.1109/AIDLNN65358.2024.00035",
        "keywords": "type:conference, application:VR, application:AR, application:UE5, method:deep_learning, method:spatialization, theme:spatial_audio, theme:video_generation, evaluation:user_study, evaluation:statistical_analysis, feature:immersive_experience, feature:audio_visual",
        "publisher": "IEEE",
        "series": "AIDLNN",
        "title": "The Application of AI Video Generation Technology in Virtual Reality (VR) and Augmented Reality (AR)",
        "type": "article",
        "url": "papers_pdf/deng2024.pdf",
        "year": "2024"
    },
    "ferreira2023": {
        "abstract": "This study applies deep learning models to symbolic music composition, focusing on generating MIDI-based music for VR applications. The authors train a recurrent neural network (RNN) on a dataset of classical music, achieving a 90% fidelity rate in generated compositions, as measured by quantitative metrics. The generated music is tested in VR environments, demonstrating its potential for integration with UE5 to create immersive audio experiences.",
        "address": "Basel, Switzerland",
        "author": "Ferreira, Pedro and Limongi, Ricardo and F\u00e1vero, Luiz Paulo",
        "doi": "10.3390/app13074543",
        "issn": "2076-3417",
        "journal": "Applied Sciences",
        "keywords": "type:article, application:VR, application:UE5, method:deep_learning, method:RNN, theme:music_generation, theme:symbolic_composition, evaluation:quantitative_metrics, feature:immersive_experience, data:MIDI",
        "number": "7",
        "pages": "4543",
        "publisher": "MDPI",
        "series": "Applied Sciences",
        "title": "Generating Music with Data: Application of Deep Learning Models for Symbolic Music Composition",
        "type": "article",
        "url": "papers_pdf/ferreira2023.pdf",
        "volume": "13",
        "year": "2023"
    },
    "mitra2025": {
        "abstract": "This systematic review examines deep learning and generative AI techniques for music generation, analyzing over 50 papers to assess their applications in VR. The authors categorize methods such as GANs and VAEs, highlighting their potential for creating immersive audio in UE5 environments. Using thematic analysis, they identify key trends and challenges, including the need for emotional expressiveness in AI-generated music.",
        "address": "Los Alamitos, CA, USA",
        "author": "Mitra, Rohan and Zualkernan, Imran",
        "doi": "10.1109/ACCESS.2025.3531798",
        "issn": "2169-3536",
        "journal": "IEEE Access",
        "keywords": "type:article, application:VR, application:UE5, method:deep_learning, method:generative_ai, method:GAN, method:VAE, theme:music_generation, evaluation:thematic_analysis, challenge:emotional_expressiveness, feature:immersive_audio",
        "pages": "18079--18106",
        "publisher": "IEEE",
        "series": "Access",
        "title": "Music Generation Using Deep Learning and Generative AI: A Systematic Review",
        "type": "article",
        "url": "papers_pdf/mitra2025.pdf",
        "volume": "13",
        "year": "2025"
    },
    "turchet2018": {
        "abstract": "This paper introduces the Internet of Musical Things (IoMT), a paradigm for connecting musical devices to enable collaborative music generation in virtual environments. The authors discuss its potential for VR applications, identifying challenges such as network latency and data interoperability. Using qualitative analysis, they assess IoMT\u2019s creativity and propose solutions for integrating it with VR systems, laying the groundwork for UE5 compatibility.",
        "address": "Los Alamitos, CA, USA",
        "author": "Turchet, Luca and Fischione, Carlo and Essl, Georg and Keller, Dami\u00e1n and Barthet, Mathieu",
        "doi": "10.1109/ACCESS.2018.2872625",
        "issn": "2169-3536",
        "journal": "IEEE Access",
        "keywords": "type:article, application:VR, method:deep_learning, theme:music_generation, theme:collaborative_music, evaluation:qualitative_analysis, feature:IoMT, challenge:network_latency, challenge:data_interoperability",
        "pages": "61994--62017",
        "publisher": "IEEE",
        "series": "Access",
        "title": "Internet of Musical Things: Vision and Challenges",
        "type": "article",
        "url": "papers_pdf/turchet2018.pdf",
        "volume": "6",
        "year": "2018"
    },
    "turchet2021": {
        "abstract": "This paper reviews the role of music in extended realities (XR), including VR, AR, and MR, with a focus on real-time audio processing challenges. The authors analyze integration issues with UE5, proposing solutions such as optimized audio pipelines. Using thematic analysis, they identify key barriers, including latency and system compatibility, and provide insights for enhancing music in UE5-based VR applications.",
        "address": "Los Alamitos, CA, USA",
        "author": "Turchet, Luca and Hamilton, Rob and \u00c7amci, Anil",
        "doi": "10.1109/ACCESS.2021.3052931",
        "issn": "2169-3536",
        "journal": "IEEE Access",
        "keywords": "type:article, application:VR, application:AR, application:MR, application:UE5, method:real-time, theme:audio_processing, evaluation:thematic_analysis, challenge:latency, challenge:system_compatibility, feature:extended_realities",
        "pages": "15810--15832",
        "publisher": "IEEE",
        "series": "Access",
        "title": "Music in Extended Realities",
        "type": "article",
        "url": "papers_pdf/turchet2021.pdf",
        "volume": "9",
        "year": "2021"
    },
    "venkatachalam2024": {
        "abstract": "This paper proposes a voice-driven AI system for generating panoramic imagery in VR, with a focus on spatial audio to enhance immersion. The system uses generative AI to create real-time audio-visual content, achieving 93% accuracy in spatial audio positioning, as validated by precision-recall analysis. The approach is tested in UE5-based VR environments, demonstrating its effectiveness in creating immersive experiences.",
        "address": "Bengaluru, India",
        "author": "Venkatachalam, Nirmala and Rayana, Mukul and S, Bala Vignesh and S, Prathamesh",
        "booktitle": "2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)",
        "doi": "10.1109/IDCIoT59759.2024.10467441",
        "keywords": "type:conference, application:VR, application:UE5, method:generative_ai, method:spatialization, theme:spatial_audio, theme:panoramic_imagery, evaluation:precision_recall, feature:voice_driven, feature:immersive_experience",
        "publisher": "IEEE",
        "series": "IDCIoT",
        "title": "Voice - Driven Panoramic Imagery: Real-Time Generative AI for Immersive Experiences",
        "type": "article",
        "url": "papers_pdf/venkatachalam2024.pdf",
        "year": "2024"
    },
    "wang2021": {
        "abstract": "This paper explores the application of AI in VR for digital media art creation, with a focus on real-time audio processing to enhance artistic expression. The authors propose an AI-based framework for audio rendering, achieving a 20% efficiency gain in rendering speed, as measured by performance metrics on synthetic datasets. The framework is designed for integration with UE5, addressing challenges in system compatibility.",
        "address": "Chongqing, China",
        "author": "Wang, Xiaoyan and Sun, Yi",
        "booktitle": "2021 2nd International Conference on Information Science and Education (ICISE-IE)",
        "doi": "10.1109/ICISE-IE53922.2021.00369",
        "keywords": "type:conference, application:VR, application:UE5, method:real-time, theme:audio_processing, theme:digital_art, evaluation:performance_metrics, challenge:system_compatibility, feature:artistic_expression",
        "publisher": "IEEE",
        "series": "ICISE-IE",
        "title": "Artificial intelligence application of virtual reality technology in digital media art creation",
        "type": "article",
        "url": "papers_pdf/wang2021.pdf",
        "year": "2021"
    },
    "wu2022": {
        "abstract": "This paper applies AI to spatial audio for VR digital art production, focusing on creating immersive soundscapes compatible with UE5. The author develops an AI-driven system for audio spatialization, achieving a 90% satisfaction rate in expert reviews (n",
        "address": "London, UK",
        "author": "Wu, Yunxuan",
        "doi": "10.1155/2022/3781750",
        "issn": "1687-5265",
        "journal": "Computational Intelligence and Neuroscience",
        "keywords": "type:article, application:VR, application:UE5, method:spatialization, theme:spatial_audio, theme:digital_art, evaluation:expert_reviews, feature:immersive_soundscapes, feature:digital_media",
        "pages": "3781750",
        "publisher": "Hindawi",
        "series": "CIN",
        "title": "Application of Artificial Intelligence within Virtual Reality for Production of Digital Media Art",
        "type": "article",
        "url": "papers_pdf/wu2022.pdf",
        "year": "2022"
    }
};